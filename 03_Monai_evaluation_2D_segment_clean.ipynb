{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aeb709e",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd67f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import monai\n",
    "from monai.data import create_test_image_2d, list_data_collate, decollate_batch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import Activations, AddChanneld, AsDiscrete, Compose, LoadImaged, SaveImage, ScaleIntensityd, EnsureTyped, EnsureType, AsChannelFirstd, Resized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb49be",
   "metadata": {},
   "source": [
    "# Check MONAI configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe0c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab45e9ae",
   "metadata": {},
   "source": [
    "# Process VGH data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c82a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Data folder\n",
    "data_path = \"/Workspace/data/VGH_Seg_IMG_Label/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35b1bc",
   "metadata": {},
   "source": [
    "## -obtain testing data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcfcaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load testing files\n",
    "tempdir = data_path + \"Test/img/\"\n",
    "test_images = sorted(glob(os.path.join(tempdir, \"*.jpg\")))\n",
    "\n",
    "tempdir = data_path + \"Test/msk_img/\"\n",
    "test_segs = sorted(glob(os.path.join(tempdir, \"*.png\")))\n",
    "\n",
    "test_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(test_images[:], test_segs[:])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e69c02",
   "metadata": {},
   "source": [
    "# Define Transform for image and Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b9e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms for image and segmentation\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "        \n",
    "        AddChanneld(keys=[\"seg\"]),        \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "\n",
    "        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "        #Resized(keys=[\"img\", \"seg\"], spatial_size=[800, 800]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")\n",
    "test_ds = monai.data.Dataset(data=test_files, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb98f41",
   "metadata": {},
   "source": [
    "# Create Data Loader, Save Output, Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc300b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliding window inference need to input 1 image in every iteration\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "saver = SaveImage(output_dir=\"./output\", output_ext=\".png\", output_postfix=\"seg\",scale=255,separate_folder=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,\n",
    "    out_channels=1,\n",
    "    #channels=(16, 32, 64, 128, 256),\n",
    "    channels=(32, 64, 128, 256, 512),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8fc863",
   "metadata": {},
   "source": [
    "# Load previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ecf333",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"best_metric_model_segmentation2d_dict.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968247bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a45dc1",
   "metadata": {},
   "source": [
    "# Run evaluation on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6030cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = test_data[\"img\"].to(device), test_data[\"seg\"].to(device)\n",
    "        # define sliding window size and batch size for windows inference\n",
    "        roi_size = (800, 800)\n",
    "        sw_batch_size = 4\n",
    "        test_outputs = sliding_window_inference(test_images, roi_size, sw_batch_size, model)\n",
    "\n",
    "        visualize( \n",
    "            image=test_images[0].cpu().permute(1,2,0), \n",
    "            ground_truth_mask=test_labels[0].cpu().permute(1,2,0), \n",
    "            predicted_mask=test_outputs[0].squeeze().cpu().numpy().round()\n",
    "        )   \n",
    "       \n",
    "        \n",
    "        test_outputs = [post_trans(i) for i in decollate_batch(test_outputs)]\n",
    "        test_labels = [post_trans(i) for i in decollate_batch(test_labels)]\n",
    "        \n",
    "        #test_labels = decollate_batch(test_labels)\n",
    "        # compute metric for current iteration\n",
    "        dice_metric(y_pred=test_outputs, y=test_labels)\n",
    "        for test_output in test_outputs:            \n",
    "            saver(test_output*255)\n",
    "    # aggregate the final mean dice result    \n",
    "    print(\"evaluation metric:\", dice_metric.aggregate().item())\n",
    "    # reset the status\n",
    "    dice_metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12194fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
